---
title: Docker Hardware Acceleration - NVENC
description: Unmanic Installation - Docker Hardware Acceleration - NVENC
id: hardware_accelerated_encoding_nvenc
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Overview

Unmanic supports hardware acceleration (HWA) of video decoding using FFmpeg. FFmpeg and Unmanic can support multiple hardware acceleration implementations such as nVidia NVENC and MediaCodec through Video Acceleration API's.


For more information on NVIDIA using FFmpeg official list, take a look [here](https://developer.nvidia.com/ffmpeg).


It is recommended to use the patched drivers [here](https://github.com/keylase/nvidia-patch) as these will remove the restriction on maximum number of simultaneous NVENC video encoding sessions imposed by Nvidia to consumer-grade GPUs.

[Here](https://developer.nvidia.com/video-encode-and-decode-gpu-support-matrix-new) is the official list of NVIDIA Graphics Cards for supported codecs.

To ensure you device is capable of running the NVENC encoders, run this command:
```
for i in encoders decoders filters; do     echo $i:; ffmpeg -hide_banner -${i} | egrep -i "npp|cuvid|nvenc|cuda|nvdec"; done
```

You should see a list of available encoders and decoders.

> NOTE:
> The minimum required NVIDIA driver version is 418.30 for this to work in Linux.



## Running Unmanic with support for NVENC

To enable NVENC, you will need to run Unmanic on a device that supports it.

If you intend to use Unmanic inside a Docker container, you will also need to pass through the required devices to the container. 

An example of this is shown below:


<Tabs
defaultValue="docker_run"
values={[
{label: 'Docker run', value: 'docker_run'},
{label: 'Docker-compose', value: 'docker_compose'},
]}>
<TabItem value="docker_run">

  ```bash
    PUID=$(id -u)
    PGID=$(id -g)

    # CONFIG_DIR - Where you settings are saved
    CONFIG_DIR=/config

    # LIBRARY_DIR - The location/locations of your library
    LIBRARY_DIR=/library

    # CACHE_DIR - A tmpfs or and folder for temporary conversion files
    CACHE_DIR=/tmp/unmanic
    
    # NVIDIA_VISIBLE_DEVICES - The GPUs that will be accessible to the container
    NVIDIA_VISIBLE_DEVICES=all

    docker run -ti --rm \
        -e PUID=${PUID} \
        -e PGID=${PGID} \
        -e NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES} \
        --runtime=nvidia \
        -p 8888:8888 \
        -v ${CONFIG_DIR}:/config \
        -v ${LIBRARY_DIR}:/library \
        -v ${CACHE_DIR}:/tmp/unmanic \
        josh5/unmanic:latest
  ```

  </TabItem>
  <TabItem value="docker_compose">

  ```yaml
    # Variables that will need to be changed:
    #     <PUID>                            -  User id for folder/file permissions
    #     <PGID>                            -  Group id for folder/file permissions
    #     <NVIDIA_VISIBLE_DEVICES>          -  The GPUs that will be accessible to the container
    #                                          Options: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html#gpu-enumeration
    #     <PATH_TO_CONFIG>                  -  Path where Unmanic will store config files
    #     <PATH_TO_LIBRARY>                 -  Path where you store the files that Unmanic will scan
    #     <PATH_TO_ENCODE_CACHE>            -  Cache path for in-progress encoding tasks
    #

    ---
    version: '2.4'
    services:
      unmanic:
        container_name: unmanic
        image: josh5/unmanic:latest
        ports:
          - 8888:8888
        environment:
          - PUID=<PUID>
          - PGID=<PGID>
          - NVIDIA_VISIBLE_DEVICES=<NVIDIA_VISIBLE_DEVICES>
        volumes:
          - <PATH_TO_CONFIG>:/config
          - <PATH_TO_LIBRARY>:/library
          - <PATH_TO_ENCODE_CACHE>:/tmp/unmanic
        runtime: nvidia       # For H/W transcoding using the NVENC encoder
  ```

  </TabItem>
</Tabs>
